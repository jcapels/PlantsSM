{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plants_sm.data_structures.dataset.multi_input_dataset import MultiInputDataset\n",
    "from plants_sm.data_standardization.proteins.standardization import ProteinStandardizer\n",
    "from plants_sm.data_standardization.compounds.deepmol_standardizers import DeepMolStandardizer\n",
    "from plants_sm.featurization.proteins.bio_embeddings.word2vec import Word2Vec\n",
    "from plants_sm.featurization.compounds.deepmol_descriptors import DeepMolDescriptors\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import Adam\n",
    "from plants_sm.models.constants import BINARY\n",
    "from plants_sm.models.pytorch_model import PyTorchModel\n",
    "from plants_sm.models.interaction.baseline_model import BaselineModel\n",
    "from plants_sm.tokenisation.compounds.smilespe import AtomLevelTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ids                                                SEQ  \\\n0    0  MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...   \n1    1  MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...   \n2    2  MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...   \n3    3  MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...   \n4    4  MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...   \n\n                  SUBSTRATES  LogSpActivity  \n0                 C(C(=O)O)N              0  \n1           C[C@@H](C(=O)O)N              1  \n2       CC(C)[C@@H](C(=O)O)N              0  \n3      CC(C)C[C@@H](C(=O)O)N              1  \n4  CC[C@H](C)[C@@H](C(=O)O)N              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ids</th>\n      <th>SEQ</th>\n      <th>SUBSTRATES</th>\n      <th>LogSpActivity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...</td>\n      <td>C(C(=O)O)N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...</td>\n      <td>C[C@@H](C(=O)O)N</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...</td>\n      <td>CC(C)[C@@H](C(=O)O)N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...</td>\n      <td>CC(C)C[C@@H](C(=O)O)N</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVL...</td>\n      <td>CC[C@H](C)[C@@H](C(=O)O)N</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset_csv = \"./data/aminotransferase_binary.csv\"\n",
    "pd.read_csv(multi_input_dataset_csv).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_input_dataset_csv = \"./multi_input_dataset.csv\"\n",
    "\n",
    "multi_input_dataset = MultiInputDataset.from_csv(file_path=multi_input_dataset_csv,\n",
    "                                                 representation_fields={\"proteins\": \"SEQ\",\n",
    "                                                                       \"ligands\": \"SUBSTRATES\"},\n",
    "                                                 instances_ids_field={\"interaction\": \"ids\"},\n",
    "                                                 labels_field=\"LogSpActivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MultiInputDataset converts everything into dictionaries to ensure that we are always processing unique sequences and not the same multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{2: 'MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVLTSVKKAEQYLLENETTKNYLGIDGIPEFGRCTQELLFGKGSALINDKRARTAQTPGGTGALRVAADFLAKNTSVKRVWVSNPSWPNHKSVFNSAGLEVREYAYYDAENHTLDFDALINSLNEAQAGDVVLFHGCCHNPTGIDPTLEQWQTLAQLSVEKGWLPLFDFAYQGFARGLEEDAEGLRAFAAMHKELIVASSYSKNFGLYNERVGACTLVAADSETVDRAFSQMKAAIRANYSNPPAHGASVVATILSNDALRAIWEQELTDMRQRIQRMRQLFVNTLQEKGANRDFSFIIKQNGMFSFSGLTKEQVLRLREEFGVYAVASGRVNVAGMTPDNMAPLCEAIVAVL',\n 1: 'MDYVTLASHAVRQYAPDQIFTASQRAKADAAALGEDAVINATLGECLDDDGKLMVLPTVERMIRQMPVEDICSYAPIAGIKGFNEAVQISLFGKCLDRFYVESVATPGGCGALRHAIWNFLNFGDALLTTNWIWGPYKNICEEHGRRMVTFDMFNRENTFNLEGMDRAIGEILAVQEQLLMILNTPANNPTGYSMTKQEMEQTVAILKKHAAANPDKNLTFCLDVSYIDFAGSFEESREIFDAIFDMPANTMTLLIFSMSKSYTMCGMRCGALVCLGSTAESAAVFKQAMSYSSRSTWSNAIHMAQKILVDINLNPEIRERVSQERAVFRNTITNRGRTFCAAAKEASLEICPYQYGYFVAIPCKNPVETARILMDQHIYVVPQAQGLRFSPCTVTTEKCRKAPAFIKAAMEQTQ',\n 3: 'MFQKVDAYAGDPILTLMERFKEDPRSDKVNLSIGLYYNEDGIIPQLQAVAEAEARLNAQPHGASLYLPMEGLNCYRHAIAPLLFGADHPVLKQQRVATIQTLGGSGALKVGADFLKRYFPESGVWVSDPTWENHVAIFAGAGFEVSTYPWYDEATNGVRFNDLLATLKTLPARSIVLLHPCCHNPTGADLTNDQWDAVIEILKARELIPFLDIAYQGFGAGMEEDAYAIRAIASAGLPALVSNSFSKIFSLYGERVGGLSVMCEDAEAAGRVLGQLKATVRRNYSSPPNFGAQVVAAVLNDEALKASWLAEVEEMRTRILAMRQELVKVLSTEMPERNFDYLLNQRGMFSYTGLSAAQVDRLREEFGVYLIASGRMCVAGLNTANVQRVAKAFAAVM'}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset.instances[\"proteins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{1: 'C(C(=O)O)N',\n 6: 'C[C@@H](C(=O)O)N',\n 5: 'CC(C)[C@@H](C(=O)O)N',\n 3: 'CC(C)C[C@@H](C(=O)O)N',\n 2: 'C1=C(NC=N1)C[C@@H](C(=O)O)N',\n 4: 'CC(C)[C@@H](C(=O)O)*'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset.instances[\"ligands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing: 100%|██████████| 3/3 [00:00<00:00, 719.39it/s]\n"
     ]
    }
   ],
   "source": [
    "multi_input_dataset = ProteinStandardizer(n_jobs=50).fit_transform(multi_input_dataset, instance_type=\"proteins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{2: 'MFENITAAPADPILGLADLFRADERPGKINLGIGVYKDETGKTPVLTSVKKAEQYLLENETTKNYLGIDGIPEFGRCTQELLFGKGSALINDKRARTAQTPGGTGALRVAADFLAKNTSVKRVWVSNPSWPNHKSVFNSAGLEVREYAYYDAENHTLDFDALINSLNEAQAGDVVLFHGCCHNPTGIDPTLEQWQTLAQLSVEKGWLPLFDFAYQGFARGLEEDAEGLRAFAAMHKELIVASSYSKNFGLYNERVGACTLVAADSETVDRAFSQMKAAIRANYSNPPAHGASVVATILSNDALRAIWEQELTDMRQRIQRMRQLFVNTLQEKGANRDFSFIIKQNGMFSFSGLTKEQVLRLREEFGVYAVASGRVNVAGMTPDNMAPLCEAIVAVL',\n 1: 'MDYVTLASHAVRQYAPDQIFTASQRAKADAAALGEDAVINATLGECLDDDGKLMVLPTVERMIRQMPVEDICSYAPIAGIKGFNEAVQISLFGKCLDRFYVESVATPGGCGALRHAIWNFLNFGDALLTTNWIWGPYKNICEEHGRRMVTFDMFNRENTFNLEGMDRAIGEILAVQEQLLMILNTPANNPTGYSMTKQEMEQTVAILKKHAAANPDKNLTFCLDVSYIDFAGSFEESREIFDAIFDMPANTMTLLIFSMSKSYTMCGMRCGALVCLGSTAESAAVFKQAMSYSSRSTWSNAIHMAQKILVDINLNPEIRERVSQERAVFRNTITNRGRTFCAAAKEASLEICPYQYGYFVAIPCKNPVETARILMDQHIYVVPQAQGLRFSPCTVTTEKCRKAPAFIKAAMEQTQ',\n 3: 'MFQKVDAYAGDPILTLMERFKEDPRSDKVNLSIGLYYNEDGIIPQLQAVAEAEARLNAQPHGASLYLPMEGLNCYRHAIAPLLFGADHPVLKQQRVATIQTLGGSGALKVGADFLKRYFPESGVWVSDPTWENHVAIFAGAGFEVSTYPWYDEATNGVRFNDLLATLKTLPARSIVLLHPCCHNPTGADLTNDQWDAVIEILKARELIPFLDIAYQGFGAGMEEDAYAIRAIASAGLPALVSNSFSKIFSLYGERVGGLSVMCEDAEAAGRVLGQLKATVRRNYSSPPNFGAQVVAAVLNDEALKASWLAEVEEMRTRILAMRQELVKVLSTEMPERNFDYLLNQRGMFSYTGLSAAQVDRLREEFGVYLIASGRMCVAGLNTANVQRVAKAFAAVM'}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset.instances[\"proteins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing: 100%|██████████| 6/6 [00:00<00:00, 881.16it/s]\n"
     ]
    }
   ],
   "source": [
    "multi_input_dataset = DeepMolStandardizer(n_jobs=50).fit_transform(multi_input_dataset, \"ligands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{1: '[H]OC(=O)C([H])([H])N([H])[H]',\n 6: '[H]OC(=O)C([H])(N([H])[H])C([H])([H])[H]',\n 5: '[H]OC(=O)C([H])(N([H])[H])C([H])(C([H])([H])[H])C([H])([H])[H]',\n 3: '[H]OC(=O)C([H])(N([H])[H])C([H])([H])C([H])(C([H])([H])[H])C([H])([H])[H]',\n 2: '[H]OC(=O)C([H])(N([H])[H])C([H])([H])c1c([H])nc([H])n1[H]',\n 4: '*C([H])(C(=O)O[H])C([H])(C([H])([H])[H])C([H])([H])[H]'}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset.instances[\"ligands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating features and encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Word2Vec: 100%|██████████| 3/3 [00:00<00:00, 1068.98it/s]\n"
     ]
    }
   ],
   "source": [
    "proteins_one_hot = Word2Vec().fit(multi_input_dataset, \"proteins\")\n",
    "multi_input_dataset = proteins_one_hot.transform(multi_input_dataset, \"proteins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepMolDescriptors: 100%|██████████| 6/6 [00:00<00:00, 33.05it/s]\n"
     ]
    }
   ],
   "source": [
    "deepmol_wrapper = DeepMolDescriptors(n_jobs=8).fit(multi_input_dataset, instance_type=\"ligands\")\n",
    "multi_input_dataset = deepmol_wrapper.transform(multi_input_dataset, instance_type=\"ligands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.0329832 , -0.01935539,  0.00307129, ..., -0.06316928,\n         0.03729028, -0.05327919],\n       [-0.0329832 , -0.01935539,  0.00307129, ..., -0.06316928,\n         0.03729028, -0.05327919],\n       [-0.0329832 , -0.01935539,  0.00307129, ..., -0.06316928,\n         0.03729028, -0.05327919],\n       ...,\n       [-0.032417  , -0.01890334,  0.00405538, ..., -0.06444652,\n         0.03711376, -0.05138807],\n       [-0.032417  , -0.01890334,  0.00405538, ..., -0.06444652,\n         0.03711376, -0.05138807],\n       [-0.032417  , -0.01890334,  0.00405538, ..., -0.06444652,\n         0.03711376, -0.05138807]], dtype=float32)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset.X[\"proteins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset.X[\"ligands\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['C',\n 'C',\n '[C@H]',\n '(',\n 'C',\n ')',\n '[C@@H]',\n '(',\n 'C',\n '(',\n '=',\n 'O',\n ')',\n 'O',\n ')',\n 'N']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AtomLevelTokenizer().tokenize(\"CC[C@H](C)[C@@H](C(=O)O)N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 14:51:33.049904: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 14:51:33.627085: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 14:51:33.627160: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 14:51:33.627166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "INFO:plants_sm.models.pytorch_model:starting to fit the data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 11\u001B[0m\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m BaselineModel(input_size_proteins, input_size_compounds, hidden_layers_proteins\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m250\u001B[39m],\n\u001B[1;32m      4\u001B[0m                       hidden_layers_compounds\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m], hidden_layers_interaction\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m])\n\u001B[1;32m      6\u001B[0m wrapper \u001B[38;5;241m=\u001B[39m PyTorchModel(model\u001B[38;5;241m=\u001B[39mmodel, loss_function\u001B[38;5;241m=\u001B[39mnn\u001B[38;5;241m.\u001B[39mBCELoss(),\n\u001B[1;32m      7\u001B[0m                                validation_metric\u001B[38;5;241m=\u001B[39mf1_score,\n\u001B[1;32m      8\u001B[0m                                problem_type\u001B[38;5;241m=\u001B[39mBINARY, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m      9\u001B[0m                                optimizer\u001B[38;5;241m=\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0001\u001B[39m), progress\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m,\n\u001B[1;32m     10\u001B[0m                                logger_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msmall_dataset.log\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mwrapper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmulti_input_dataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/PHD/PlantsSM/src/plants_sm/models/model.py:118\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, train_dataset, validation_dataset)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_dataset: Dataset, validation_dataset: Dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    Fits the model to the data.\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;124;03m    self\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/PHD/PlantsSM/src/plants_sm/models/pytorch_model.py:341\u001B[0m, in \u001B[0;36mPyTorchModel._fit_data\u001B[0;34m(self, train_dataset, validation_dataset)\u001B[0m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, inputs_targets \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataset):\n\u001B[1;32m    339\u001B[0m     actual, yhat, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train(inputs_targets)\n\u001B[0;32m--> 341\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myhat\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    342\u001B[0m     actuals \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((actuals, actual))\n\u001B[1;32m    343\u001B[0m     loss_total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "input_size_proteins = multi_input_dataset.X[\"proteins\"].shape[1]\n",
    "input_size_compounds = multi_input_dataset.X[\"ligands\"].shape[1]\n",
    "model = BaselineModel(input_size_proteins, input_size_compounds, hidden_layers_proteins=[500, 250],\n",
    "                      hidden_layers_compounds=[500, 500], hidden_layers_interaction=[500, 500])\n",
    "\n",
    "wrapper = PyTorchModel(model=model, loss_function=nn.BCELoss(),\n",
    "                               validation_metric=f1_score,\n",
    "                               problem_type=BINARY, batch_size=50, epochs=100,\n",
    "                               optimizer=Adam(model.parameters(), lr=0.0001), progress=50,\n",
    "                               logger_path=\"small_dataset.log\")\n",
    "wrapper.fit(multi_input_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
